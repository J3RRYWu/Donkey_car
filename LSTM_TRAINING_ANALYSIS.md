# LSTMè®­ç»ƒä»£ç åˆ†ææŠ¥å‘Š

## ä»£ç æ£€æŸ¥ç»“æœ

### âœ… æ²¡æœ‰æ˜æ˜¾çš„é€»è¾‘é”™è¯¯

ç»è¿‡è¯¦ç»†æ£€æŸ¥ï¼ŒLSTMè®­ç»ƒä»£ç **æ²¡æœ‰ä¸¥é‡çš„bugæˆ–é€»è¾‘é”™è¯¯**ï¼Œå®ç°æ˜¯æ­£ç¡®çš„ï¼š

1. âœ… **Teacher Forcingå®ç°æ­£ç¡®**
   - `predict_teacher_forcing`: é€æ­¥é¢„æµ‹ï¼Œæ¯æ­¥ä½¿ç”¨çœŸå®çš„å‰ä¸€çŠ¶æ€
   - é¢„æµ‹ z[t] â†’ z[t+1]ï¼Œä½¿ç”¨çœŸå®çš„z[t]ä½œä¸ºè¾“å…¥

2. âœ… **Residual Predictionæ­£ç¡®**
   - `z_next = z + f(z, a)` 
   - é¢„æµ‹å¢é‡è€Œéç»å¯¹å€¼ï¼Œç†è®ºä¸Šæ›´å®¹æ˜“å­¦ä¹ 

3. âœ… **æŸå¤±å‡½æ•°åˆç†**
   - ä½¿ç”¨MSE lossåœ¨æ½œåœ¨ç©ºé—´
   - VAE encoder/decoderè¢«å†»ç»“

4. âœ… **æ•°æ®æµæ­£ç¡®**
   - è¾“å…¥å›¾åƒ â†’ VAE encode â†’ latent â†’ LSTMé¢„æµ‹ â†’ é¢„æµ‹latent
   - Targetå›¾åƒ â†’ VAE encode â†’ target latent
   - è®¡ç®—é¢„æµ‹latentå’Œtarget latentçš„MSE

---

## ğŸ” æ ¸å¿ƒé—®é¢˜åˆ†æ

### é—®é¢˜ä¸åœ¨ä»£ç é€»è¾‘ï¼Œè€Œåœ¨è®­ç»ƒç›®æ ‡æœ¬èº«

#### é—®é¢˜1: MSE Lossä¸ä¿è¯è¯­ä¹‰

```python
# è®­ç»ƒç›®æ ‡
loss = MSE(z_pred, z_target)  # åœ¨latentç©ºé—´çš„L2è·ç¦»
```

**å±€é™æ€§**ï¼š
- MSEåªè¡¡é‡æ•°å€¼ä¸Šçš„è·ç¦»
- ä¸ä¿è¯è§£ç åçš„å›¾åƒè´¨é‡
- ä¸ä¿è¯è¯­ä¹‰ä¿¡æ¯ä¿ç•™

**ä¸¾ä¾‹**ï¼š
```
çœŸå®latent:     [0.5, 0.3, -0.2, ...]  â†’ è§£ç  â†’ æ¸…æ™°è½¦é“
é¢„æµ‹latent:     [0.48, 0.32, -0.18, ...] â†’ è§£ç  â†’ æ¨¡ç³Šè½¦é“
MSE = 0.001 (å¾ˆå°ï¼) ä½†è¯­ä¹‰å·²ä¸¢å¤±
```

#### é—®é¢˜2: VAEçš„å‹ç¼©æœ‰æŸ

VAEå°†64Ã—64Ã—3 = 12288ç»´çš„å›¾åƒå‹ç¼©åˆ°64Ã—4Ã—4 = 1024ç»´ï¼š
- **å‹ç¼©æ¯”**: 12:1
- **ä¿¡æ¯ä¸¢å¤±**: ä¸å¯é¿å…

LSTMåœ¨è¿™ä¸ª**å·²ç»æœ‰æŸçš„ç©ºé—´**è¿›è¡Œé¢„æµ‹ï¼Œè¿›ä¸€æ­¥æ”¾å¤§è¯¯å·®ã€‚

#### é—®é¢˜3: è¯¯å·®ç´¯ç§¯

```
çœŸå®å›¾åƒ â†’ VAE encode â†’ latent (å·²æœ‰æŸå¤±1)
         â†“
latent â†’ LSTM predict â†’ é¢„æµ‹latent (è¯¯å·®2)
         â†“
é¢„æµ‹latent â†’ VAE decode â†’ é¢„æµ‹å›¾åƒ (è¯¯å·®3)
```

**æ€»è¯¯å·® = ç¼–ç æŸå¤± + é¢„æµ‹æŸå¤± + è§£ç æŸå¤±**

---

## ğŸ¯ ä¸ºä»€ä¹ˆè®­ç»ƒlossä¸‹é™ä½†æ•ˆæœå·®ï¼Ÿ

### ç°è±¡
```
Training Loss: 0.005 â†’ 0.001 (ä¸‹é™80%)
Validation Loss: 0.008 â†’ 0.003 (ä¸‹é™62.5%)
```

çœ‹èµ·æ¥å¾ˆå¥½ï¼ä½†å®é™…æ•ˆæœå·®ï¼ŒåŸå› ï¼š

### 1. **Losså’Œå®é™…ä»»åŠ¡ä¸å¯¹é½**

| è®­ç»ƒä¼˜åŒ–çš„æŒ‡æ ‡ | å®é™…éœ€è¦çš„æŒ‡æ ‡ |
|---------------|--------------|
| Latent MSE (å°) | å›¾åƒè´¨é‡ (å¥½) |
| æ•°å€¼æ¥è¿‘ | è¯­ä¹‰ä¿ç•™ |
| L2è·ç¦» | å¯åˆ†ç±»æ€§ |

**è¿™æ˜¯æ ¹æœ¬æ€§çš„ä¸åŒ¹é…ï¼**

### 2. **è¿‡æ‹Ÿåˆåˆ°è®­ç»ƒåˆ†å¸ƒ**

LSTMå­¦ä¼šäº†ï¼š
- âœ… é¢„æµ‹è®­ç»ƒé›†ä¸­çš„latent pattern
- âŒ ä½†è¿™äº›patternè§£ç åè¯­ä¹‰ä¸¢å¤±

### 3. **VAEæ½œåœ¨ç©ºé—´ä¸å¤Ÿrobust**

- VAEè®­ç»ƒæ—¶åªä¼˜åŒ–é‡å»ºloss
- æ½œåœ¨ç©ºé—´æ²¡æœ‰è¢«çº¦æŸä¿æŒè¯­ä¹‰
- å°çš„latentæ‰°åŠ¨å¯èƒ½å¯¼è‡´å¤§çš„è¯­ä¹‰å˜åŒ–

---

## ğŸ’¡ æ”¹è¿›æ–¹å‘

### çŸ­æœŸæ”¹è¿›ï¼ˆä¸æ”¹æ¶æ„ï¼‰

#### 1. æ·»åŠ æ„ŸçŸ¥æŸå¤± (Perceptual Loss)
```python
# ä¸åªä¼˜åŒ–latent MSEï¼Œè¿˜è¦ä¼˜åŒ–è§£ç åçš„å›¾åƒç‰¹å¾
z_pred = lstm(z)
img_pred = vae.decode(z_pred)
img_target = vae.decode(z_target)

# ä½¿ç”¨é¢„è®­ç»ƒCNNæå–ç‰¹å¾
features_pred = pretrained_cnn(img_pred)
features_target = pretrained_cnn(img_target)

loss = mse_loss(z_pred, z_target) + Î» * mse_loss(features_pred, features_target)
```

**ä¼˜åŠ¿**: ç›´æ¥ä¼˜åŒ–è§£ç å›¾åƒçš„è¯­ä¹‰ç‰¹å¾

#### 2. æ·»åŠ å¯¹æŠ—æŸå¤± (GAN)
```python
# è®©åˆ¤åˆ«å™¨åŒºåˆ†çœŸå®latentå’Œé¢„æµ‹latent
loss_adv = discriminator_loss(z_pred, z_target)
loss = mse_loss + Î»_adv * loss_adv
```

**ä¼˜åŠ¿**: å¼ºåˆ¶é¢„æµ‹çš„latentåˆ†å¸ƒæ¥è¿‘çœŸå®åˆ†å¸ƒ

#### 3. æ·»åŠ åˆ†ç±»è¾…åŠ©æŸå¤±
```python
# åœ¨latentä¸Šè®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨
label_pred = classifier(z_pred)
label_target = get_visual_label(img_target)

loss = mse_loss + Î»_cls * cross_entropy(label_pred, label_target)
```

**ä¼˜åŠ¿**: ç›´æ¥ä¼˜åŒ–ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½

### ä¸­æœŸæ”¹è¿›ï¼ˆé‡æ–°è®­ç»ƒï¼‰

#### 1. æ”¹è¿›VAE
- å¢å¤§latent_dim: 64 â†’ 128/256
- ä½¿ç”¨æ›´æ·±çš„ç½‘ç»œ
- æ·»åŠ skip connections
- ä½¿ç”¨æ„ŸçŸ¥æŸå¤±è®­ç»ƒVAE

#### 2. ç«¯åˆ°ç«¯è®­ç»ƒ
```python
# è”åˆè®­ç»ƒVAE + LSTM + Classifier
total_loss = reconstruction_loss + prediction_loss + classification_loss
```

**ä¼˜åŠ¿**: æ•´ä¸ªpipelineä¸ºæœ€ç»ˆä»»åŠ¡ä¼˜åŒ–

### é•¿æœŸæ–¹æ¡ˆï¼ˆæ¶æ„é‡è®¾è®¡ï¼‰

#### 1. ä½¿ç”¨Diffusion Modelä»£æ›¿VAE
- æ›´å¥½çš„ç”Ÿæˆè´¨é‡
- æ›´robustçš„æ½œåœ¨ç©ºé—´

#### 2. ä½¿ç”¨Transformerä»£æ›¿LSTM
- æ›´å¼ºçš„é•¿ç¨‹ä¾èµ–å»ºæ¨¡
- æ³¨æ„åŠ›æœºåˆ¶

#### 3. ç›´æ¥åœ¨åƒç´ ç©ºé—´é¢„æµ‹
- è·³è¿‡VAEï¼Œé¿å…ä¿¡æ¯æŸå¤±
- ä½¿ç”¨video predictionæ¨¡å‹

---

## ğŸ“Š å…·ä½“è®­ç»ƒå‚æ•°æ£€æŸ¥

### å½“å‰é…ç½®ï¼ˆéœ€è¦ç¡®è®¤ï¼‰
```python
--epochs 40
--batch_size 4
--lr 1e-4
--hidden_size 256
--predictor lstm
--residual_prediction  # âœ…
--scheduled_sampling    # âœ…
--use_actions          # âœ…
```

### å»ºè®®è°ƒæ•´

#### 1. å¢åŠ è®­ç»ƒepoch
```bash
--epochs 100  # å½“å‰40å¯èƒ½ä¸å¤Ÿ
```

#### 2. å¢åŠ æ¨¡å‹å®¹é‡
```bash
--hidden_size 512  # ä»256å¢åŠ 
```

#### 3. ä½¿ç”¨å­¦ä¹ ç‡è¡°å‡
```bash
--lr_schedule cosine  # æˆ– --lr_schedule step
```

#### 4. å¢åŠ æ•°æ®å¢å¼º
```bash
--input_noise_std 0.01  # è¾“å…¥å™ªå£°
--target_jitter_scale 0.005  # Targetæ‰°åŠ¨
```

---

## ğŸ”¬ è¯Šæ–­å»ºè®®

### 1. æ£€æŸ¥latent spaceè´¨é‡
```python
# çœŸå®å›¾åƒencode-decode
img_real â†’ encode â†’ z_real â†’ decode â†’ img_recon
mse(img_real, img_recon) = ?  # åº”è¯¥å¾ˆå°

# LSTMé¢„æµ‹çš„latent decode
z_pred â†’ decode â†’ img_pred
visual_quality(img_pred) = ?  # åº”è¯¥æ¸…æ™°
```

### 2. å¯è§†åŒ–latent space
```python
# t-SNEå¯è§†åŒ–çœŸå®latent vs é¢„æµ‹latent
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2)
z_real_2d = tsne.fit_transform(z_real)
z_pred_2d = tsne.transform(z_pred)
plt.scatter(z_real_2d, label='Real')
plt.scatter(z_pred_2d, label='Predicted')
```

### 3. åˆ†æé¢„æµ‹è¯¯å·®åˆ†å¸ƒ
```python
# å“ªäº›æ—¶é—´æ­¥è¯¯å·®å¤§ï¼Ÿ
errors_per_step = [(z_pred[t] - z_real[t])**2 for t in range(T)]
plt.plot(errors_per_step)  # è¯¯å·®æ˜¯å¦ç´¯ç§¯ï¼Ÿ
```

---

## âœ… æœ€ç»ˆç»“è®º

### ä»£ç å±‚é¢
- **æ— æ˜æ˜¾bug** âœ…
- å®ç°ç¬¦åˆè®ºæ–‡æ ‡å‡†åšæ³•
- Teacher Forcingã€Residualã€Scheduled Samplingéƒ½æ­£ç¡®

### æ–¹æ³•è®ºå±‚é¢
- **è®­ç»ƒç›®æ ‡ä¸å®é™…ä»»åŠ¡ä¸å¯¹é½** âŒ
- MSE lossä¸ä¿è¯è¯­ä¹‰ä¿ç•™
- éœ€è¦æ·»åŠ ä»»åŠ¡ç›¸å…³çš„æŸå¤±å‡½æ•°

### å»ºè®®
1. **çŸ­æœŸ**: æ·»åŠ æ„ŸçŸ¥æŸå¤±æˆ–åˆ†ç±»è¾…åŠ©æŸå¤±
2. **ä¸­æœŸ**: ç«¯åˆ°ç«¯è”åˆè®­ç»ƒ
3. **é•¿æœŸ**: è€ƒè™‘æ›´å¼ºçš„ç”Ÿæˆæ¨¡å‹ï¼ˆDiffusionï¼‰

**æ ¸å¿ƒé—®é¢˜ä¸æ˜¯è®­ç»ƒæœ‰bugï¼Œè€Œæ˜¯æ–¹æ³•æœ¬èº«çš„å±€é™æ€§ï¼**
